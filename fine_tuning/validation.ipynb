{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4fd2c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for: rate01-50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\ByteMentor\\sandbox\\wandb\\run-20250511_165408-tqiwxk3h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/tqiwxk3h' target=\"_blank\">rate01-50</a></strong> to <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/tqiwxk3h' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/tqiwxk3h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\ByteMentor\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: What is the core concept of Explorative_Datenanalyse, focusing on data discovery?\n",
      "Output: What is the core concept of Explorative_Datenanalyse, focusing on data discovery?\n",
      "\n",
      "**Explorative_Datenanalyse** is a research area that focuses on the **discovery of patterns and relationships** in **unstructured and semi-structured data**. This involves a **multi-step process** that includes data cleaning, data transformation, data exploration, and data mining.\n",
      "\n",
      "**Key concepts in data discovery include:**\n",
      "\n",
      "* **Data exploration:** The process of **discovering and understanding the data** through visual analysis, data mining, and statistical techniques.\n",
      "* **Data mining:**\n",
      "\n",
      "\n",
      "Prompt: What is the principle of distance calculation in Informatik_Programieren?\n",
      "Output: What is the principle of distance calculation in Informatik_Programieren?\n",
      "\n",
      "The principle of distance calculation in Informatik_Programieren is based on the idea that the distance between two points can be calculated based on the difference between their coordinates. This principle can be used to find the shortest path between two points, the distance between two sets of data, or the distance between two images.\n",
      "\n",
      "Here are the key points of the principle of distance calculation:\n",
      "\n",
      "* The distance between two points is calculated based on the difference between their coordinates.\n",
      "* The coordinates of the two\n",
      "\n",
      "\n",
      "Prompt: What is the fundamental principle behind line integral in Lineare_Algebra?\n",
      "Output: What is the fundamental principle behind line integral in Lineare_Algebra?\n",
      "\n",
      "A line integral is a function that assigns to each closed curve a real number. The fundamental principle behind line integral is that it gives a way to compute the total amount of a function along a closed curve.\n",
      "\n",
      "The line integral is defined as the limit of the sum of the function values evaluated at points along the curve as the number of points approaches infinity.\n",
      "\n",
      "The line integral is a linear functional, which means that it is linear with respect to the choice of parameterization. This means that the\n",
      "\n",
      "\n",
      "Prompt: What is the concept of overfitting in machine learning?\n",
      "Output: What is the concept of overfitting in machine learning?\n",
      "\n",
      "Overfitting is a phenomenon in machine learning (ML) where a model becomes too closely fit to the training data, resulting in poor generalization performance on unseen data. This can occur when the model is too complex or when the training data is not representative of the real-world data.\n",
      "\n",
      "**Key characteristics of overfitting:**\n",
      "\n",
      "* **High training accuracy:** The model achieves high accuracy on the training data, indicating that it can perfectly reproduce the training patterns.\n",
      "* **Low generalization accuracy:** When\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rate01-50</strong> at: <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/tqiwxk3h' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/tqiwxk3h</a><br> View project at: <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250511_165408-tqiwxk3h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for: rate2e-4-500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\ByteMentor\\sandbox\\wandb\\run-20250511_165502-z12d016p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/z12d016p' target=\"_blank\">rate2e-4-500</a></strong> to <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/z12d016p' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/z12d016p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\ByteMentor\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: What is the core concept of Explorative_Datenanalyse, focusing on data discovery?\n",
      "Output: What is the core concept of Explorative_Datenanalyse, focusing on data discovery?\n",
      "\n",
      "**Explorative_Datenanalyse** is a data science approach that focuses on **uncovering and understanding data** through a **creative and iterative process**. It emphasizes the **discovery of patterns and relationships** in data, rather than just analyzing pre-defined variables or hypotheses.\n",
      "\n",
      "At the core of this approach is the concept of **data discovery**, which involves the following steps:\n",
      "\n",
      "* **Data identification:** Identifying the data sources and types you want to explore.\n",
      "* **Data exploration:** Brows\n",
      "\n",
      "\n",
      "Prompt: What is the principle of distance calculation in Informatik_Programieren?\n",
      "Output: What is the principle of distance calculation in Informatik_Programieren?\n",
      "\n",
      "The principle of distance calculation in Informatik_Programieren states that the distance between two points is the number of steps it would take to move from one point to the other. This principle is used in various algorithms, such as the nearest neighbor search and the Euclidean distance calculation.\n",
      "\n",
      "In Informatik_Programieren, the principle of distance calculation is expressed using the 'Distance' data type. This data type represents the number of steps required to move between two points in a specified coordinate system.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Prompt: What is the fundamental principle behind line integral in Lineare_Algebra?\n",
      "Output: What is the fundamental principle behind line integral in Lineare_Algebra?\n",
      "\n",
      "$$\\int_a^b L(\\vec{x}, t) d\\vec{x}$$\n",
      "\n",
      "where L is a vector function, a and b are real numbers, and d\\vec{x} is the vector differential.\n",
      "\n",
      "The fundamental principle behind line integral in Lineare_Algebra is the **concept of the integral as a multi-dimensional limit**. \n",
      "\n",
      "In simpler terms, it states that the line integral represents the limit of the sum of the values of the function L evaluated\n",
      "\n",
      "\n",
      "Prompt: What is the concept of overfitting in machine learning?\n",
      "Output: What is the concept of overfitting in machine learning?\n",
      "\n",
      "Overfitting is when a machine learning model becomes too closely fit to the training data, rather than generalizing well to new data. This can lead to poor performance on unseen data, as the model has not learned the underlying patterns in the data.\n",
      "\n",
      "**Key concepts:**\n",
      "\n",
      "* **Statistical inference:** Machine learning models are trained to make predictions or decisions based on data.\n",
      "* **Generalization:** The goal of machine learning is to build models that can perform well on unseen data.\n",
      "*\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rate2e-4-500</strong> at: <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/z12d016p' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/z12d016p</a><br> View project at: <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250511_165502-z12d016p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for: rate2e-2-10000_checkpoint-5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Projects\\ByteMentor\\sandbox\\wandb\\run-20250511_165553-x8wj7sx7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/x8wj7sx7' target=\"_blank\">rate2e-2-10000_checkpoint-5000</a></strong> to <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/x8wj7sx7' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/x8wj7sx7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\ByteMentor\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: What is the core concept of Explorative_Datenanalyse, focusing on data discovery?\n",
      "Output: What is the core concept of Explorative_Datenanalyse, focusing on data discovery?\n",
      "\n",
      "\n",
      "Prompt: What is the principle of distance calculation in Informatik_Programieren?\n",
      "Output: What is the principle of distance calculation in Informatik_Programieren?\n",
      "\n",
      "\n",
      "Prompt: What is the fundamental principle behind line integral in Lineare_Algebra?\n",
      "Output: What is the fundamental principle behind line integral in Lineare_Algebra?\n",
      "\n",
      "\n",
      "Prompt: What is the concept of overfitting in machine learning?\n",
      "Output: What is the concept of overfitting in machine learning?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rate2e-2-10000_checkpoint-5000</strong> at: <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/x8wj7sx7' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison/runs/x8wj7sx7</a><br> View project at: <a href='https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison' target=\"_blank\">https://wandb.ai/tomic_nikola1996-zhaw/gemma-comparison</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250511_165553-x8wj7sx7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Your local model paths\n",
    "model_paths = {\n",
    "    \"rate01-50\": \"D:/Projects/ByteMentor/models/rate01-50\",\n",
    "    \"rate2e-4-500\": \"D:/Projects/ByteMentor/models/rate2e-4-500\",\n",
    "    \"rate2e-2-10000_checkpoint-5000\": \"D:/Projects/ByteMentor/models/rate2e-2-10000_checkpoint-5000\"\n",
    "}\n",
    "\n",
    "# Evaluation prompts\n",
    "prompts = [\n",
    "    \"What is the core concept of Explorative_Datenanalyse, focusing on data discovery?\",\n",
    "    \"What is the principle of distance calculation in Informatik_Programieren?\",\n",
    "    \"What is the fundamental principle behind line integral in Lineare_Algebra?\",\n",
    "    \"What is the concept of overfitting in machine learning?\"\n",
    "]\n",
    "\n",
    "# Evaluation function with W&B logging\n",
    "def evaluate_and_log(model_dir, run_name, prompts):\n",
    "    print(f\"Running evaluation for: {run_name}\")\n",
    "    wandb.init(project=\"gemma-comparison\", name=run_name)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_dir).cuda()\n",
    "    model.eval()\n",
    "\n",
    "    # Create a W&B Table to log all prompt-output pairs\n",
    "    table = wandb.Table(columns=[\"Prompt\", \"Output\"])\n",
    "\n",
    "    for prompt in prompts:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, max_new_tokens=100)\n",
    "        decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        print(f\"\\nPrompt: {prompt}\\nOutput: {decoded}\\n\")\n",
    "\n",
    "        table.add_data(prompt, decoded)\n",
    "\n",
    "    # Log the full table once at the end\n",
    "    wandb.log({\"Prompt-Output Table\": table})\n",
    "    wandb.finish()\n",
    "\n",
    "# Run evaluation for each model\n",
    "for run_name, path in model_paths.items():\n",
    "    evaluate_and_log(path, run_name, prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719cfc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the concept of overfitting in machine learning?\n",
      "\n",
      "Output: What is the concept of overfitting in machine learning?\n",
      "\n",
      "Overfitting is when a machine learning model becomes too closely fit to the training data, rather than generalizing well to new data. This can lead to poor performance on unseen data, as the model has not learned the underlying patterns in the data.\n",
      "\n",
      "**Key concepts:**\n",
      "\n",
      "* **Statistical inference:** Machine learning models are trained to make predictions or decisions based on data.\n",
      "* **Generalization:** The goal of machine learning is to build models that can perform well on unseen data.\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Set the model you want to test\n",
    "model_path = \"D:/Projects/ByteMentor/models/rate2e-4-500\"  # Change to any of your model folders\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).cuda()\n",
    "model.eval()\n",
    "\n",
    "# Define your prompt\n",
    "prompt = \"What is the concept of overfitting in machine learning?\"\n",
    "\n",
    "# Tokenize and generate output\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "# Decode and print result\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(f\"Prompt: {prompt}\\n\\nOutput: {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
