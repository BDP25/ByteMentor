{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_dir = \"../data/sample/raw/\"\n",
    "data_extracted_dir = \"../data/sample/extracted/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def save_text_to_json(\n",
    "    filename_orignial: str,\n",
    "    current_dir: str,\n",
    "    text: str,\n",
    "    extract_dir: str = \"../data/sample/extracted/\",\n",
    ") -> None:\n",
    "    filename_json = extract_dir + os.path.splitext(filename_orignial)[0] + \".json\"\n",
    "\n",
    "    # Keywords is the folder structure. Example: Analysis/3/Lectures/filename -> [Analysis, 3, Lectures]\n",
    "    keywords = [part for part in re.split(r\"[\\\\/]\", current_dir) if part]\n",
    "\n",
    "    data = {\"Key-Words\": keywords, \"content\": text}\n",
    "    with open(filename_json, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en', 'de')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    DetectorFactory.seed = 0  # Ensure consistency in detection\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        return language\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "(\n",
    "    detect_language(text=\"Hello this is a text\"),\n",
    "    detect_language(text=\"Hallo das ist ein text\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sentence. This is a test.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "\n",
    "def translate_text(text: str, src_lang: str, dest_lang: str) -> str:\n",
    "    try:\n",
    "        translated = GoogleTranslator(source=src_lang, target=dest_lang).translate(text)\n",
    "        return translated\n",
    "    except Exception as e:\n",
    "        return f\"Translation failed: {e}\"\n",
    "\n",
    "\n",
    "translate_text(\n",
    "    text=\"Das ist ein Satz. Das ist ein Test.\", src_lang=\"de\", dest_lang=\"en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\damia\\Github\\ZHAW\\PM4\\ByteMentor\\data_utils\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "filename = \"Einheitliches Referenz Skript.pdf\"\n",
    "save_text_to_json(\n",
    "    filename_orignial=filename,\n",
    "    current_dir=data_raw_dir,\n",
    "    text=extract_text_from_pdf(pdf_path=data_raw_dir + filename),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "\n",
    "\n",
    "def extract_text_from_pptx(pptx_path: str) -> str:\n",
    "    presentation = Presentation(pptx_path)\n",
    "    text = \"\"\n",
    "    for slide in presentation.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if hasattr(shape, \"text\"):\n",
    "                text += shape.text\n",
    "    return text\n",
    "\n",
    "\n",
    "filename = \"DENT_SW2_Market and Environment Analysis_ppt templates.pptx\"\n",
    "save_text_to_json(\n",
    "    filename_orignial=filename,\n",
    "    current_dir=data_raw_dir,\n",
    "    text=extract_text_from_pptx(pptx_path=data_raw_dir + filename),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "\n",
    "def extract_text_from_docx(docx_path: str) -> str:\n",
    "    doc = Document(docx_path)\n",
    "    text = \"\"\n",
    "    for para in doc.paragraphs:\n",
    "        text += para.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "filename = \"3.1 Projektcharta Vorlage.docx\"\n",
    "save_text_to_json(\n",
    "    filename_orignial=filename,\n",
    "    current_dir=data_raw_dir,\n",
    "    text=extract_text_from_docx(docx_path=data_raw_dir + filename),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZHAW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
